Name,Link
BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation,https://github.com/mit-han-lab/bevfusion
DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries,https://github.com/WangYueFt/detr3d
Spatiotemporal Transformer Attention Network for 3D Voxel Level Joint Segmentation and Motion Prediction in Point Cloud,https://arxiv.org/pdf/2203.00138.pdf
BEVFormer: a Cutting-edge Baseline for Camera-based Detection,https://github.com/zhiqi-li/BEVFormer
BirdNet+: End-to-End 3D Object Detection in LiDAR Bird’s Eye View,https://github.com/AlejandroBarrera/birdnet2
Center-based 3D Object Detection and Tracking,https://github.com/tianweiy/CenterPoint
Multimodal Virtual Point 3D Detection,https://github.com/tianweiy/MVP
JackRabbot Dataset and Benchmark (JRDB),https://jrdb.erc.monash.edu/
JMODT: Joint Multi-Object Detection and Tracking with Camera-LiDAR Fusion for Autonomous Driving,https://github.com/Kemo-Huang/JMODT
You Don't Only Look Once: Constructing Spatial-Temporal Memory for Integrated 3D Object Detection and Tracking,https://zju3dv.github.io/UDOLO/
3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds,https://github.com/fpthink/V2B
Robust Multi-Modality Multi-Object Tracking,https://github.com/ZwwWayne/mmMOT
The H3D Dataset for Full-Surround 3D Multi-Object Detection and Tracking in Crowded Urban Scenes,https://arxiv.org/abs/1903.01568
Monocular BEV Perception with Transformers in Autonomous Driving,https://towardsdatascience.com/monocular-bev-perception-with-transformers-in-autonomous-driving-c41e4a893944
Perception for Automated Trucking,https://medium.com/ike-blog/perception-for-automated-trucking-c8a8c12e1015
Joint 3D Object Detection and Tracking Using Spatio-Temporal Representation of Camera Image and LiDAR Point Clouds,https://arxiv.org/abs/2112.07116
Position Embedding Transformation for Multi-View 3D Object Detection,https://github.com/megvii-research/PETR
Geometry-guided Kernel Transformer,https://github.com/hustvl/GKT
3D-CVF: Generating Joint Camera and LiDAR Features Using Cross-View Spatial Feature Fusion for 3D Object Detection,https://arxiv.org/pdf/2004.12636.pdf
Deep Continuous Fusion for Multi-Sensor 3D Object Detection,https://openaccess.thecvf.com/content_ECCV_2018/papers/Ming_Liang_Deep_Continuous_Fusion_ECCV_2018_paper.pdf
M^2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Bird’s-Eye View Representation,https://nvlabs.github.io/M2BEV/
CLOCs: Camera-LiDAR Object Candidates Fusion for 3D Object Detection,https://github.com/pangsu0613/CLOCs
Fast-CLOCs: Fast Camera-LiDAR Object Candidates Fusion for 3D Object Detection,https://openaccess.thecvf.com/content/WACV2022/papers/Pang_Fast-CLOCs_Fast_Camera-LiDAR_Object_Candidates_Fusion_for_3D_Object_Detection_WACV_2022_paper.pdf
3DETR: An End-to-End Transformer Model for 3D Object Detection,https://github.com/facebookresearch/3detr
Score refinement for confidence-based 3D multi-object tracking,https://github.com/cogsys-tuebingen/CBMOT